{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5yvf74zO-P9c"
   },
   "source": [
    "# üöÄ Tecton Quickstart\n",
    "---\n",
    "\n",
    "Want to see what Tecton can do? In this 10-minute quickstart, you'll build a streaming feature pipeline that can process real-time transaction data and serve features with millisecond latency. Perfect for fraud detection, real-time recommendations, or any application that needs fresh feature values.\n",
    "\n",
    "### What You'll Build\n",
    "\n",
    "We'll create a simple but powerful feature pipeline that:\n",
    "\n",
    "- Ingests streaming transaction data in real-time\n",
    "- Computes running totals over different time windows\n",
    "- Serves feature values with sub-second latency\n",
    "\n",
    "### What You'll Learn\n",
    "\n",
    "- How to define features in Tecton using Python\n",
    "- How to test features directly in your notebook\n",
    "- How to ingest real-time data and see immediate updates\n",
    "\n",
    "No prior Tecton experience needed - if you're comfortable with Python, you can complete this tutorial. Ready to get started?\n",
    "\n",
    "##### üí° **NOT YET A TECTON USER?**\n",
    "\n",
    "Sign-up at [explore.tecton.ai](https://explore.tecton.ai) for a free account that lets you try out this tutorial and explore Tecton's Web UI.\n",
    "\n",
    "---\n",
    "\n",
    "Tecton helps you build and productionize AI applications by making it easy to define, test, and deploy features for model training and serving.\n",
    "\n",
    "Let's take a quick look at how you can build a low-latency streaming feature for a fraud detection use case using nothing but Python.\n",
    "\n",
    "For an end-to-end tutorial that takes you from raw data to a real-time model, check out [Building a Production AI Application with Tecton](https://docs.tecton.ai/docs/tutorials/building-a-production-ai-application)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFP0foTdHPPN"
   },
   "source": [
    "## ‚öôÔ∏è Install Tecton\n",
    "\n",
    "First things first, let's install the Tecton SDK and other libraries used in this tutorial by running the cell below.\n",
    "\n",
    "**NOTE**: When the `pip install` is finished you will need to restart the session in order to continue. Click \"Restart session\" in the dialog box or in the notebook cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ocOCkQN7uyNd"
   },
   "outputs": [],
   "source": [
    "!pip install 'tecton[rift]==1.1.0' gcsfs s3fs --force"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZOipgTDAFw-J"
   },
   "source": [
    "## ‚úÖ Log in to Tecton\n",
    "\n",
    "Make sure to hit `enter` after pasting in your authentication token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4wBVfvjZvI-n"
   },
   "outputs": [],
   "source": [
    "import tecton\n",
    "\n",
    "tecton.login(\"https://explore.tecton.ai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it for setup! Your environment is ready for building features. Let's create your first streaming feature pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ESNW-bgrF0hU"
   },
   "source": [
    "## üß™ Define and test a streaming feature\n",
    "\n",
    "Using Tecton's Feature Engineering Framework we will define 3 new features for our fraud detection model:\n",
    "\n",
    "- A user's total transaction amount in the last 1 minute\n",
    "- A user's total transaction amount in the last 1 hour\n",
    "- A user's total transaction amount in the last 30 days\n",
    "\n",
    "To do so, we will first define a [Stream Source](https://docs.tecton.ai/docs/defining-features/data-sources/creating-a-data-source/creating-and-testing-a-push-source) which tells Tecton where to retrieve events online and offline. For the online path, we've configured Tecton to accept real-time events via an HTTP ingestion API which we will try sending records to in the next step. For the offline path, we've pointed Tecton to an S3 path that contains a historical record of our stream. Tecton uses this path for offline development and backfills.\n",
    "\n",
    "Next we define a [Stream Feature View](https://docs.tecton.ai/docs/defining-features/feature-views/stream-feature-view/stream-feature-view-with-rift) which can create one or more features via transformations against the Stream Source. In a Stream Feature View, we can run Python transformations on incoming records, and optionally apply time-windowed [aggregations](https://docs.tecton.ai/docs/defining-features/feature-types/aggregation-engine) via the `aggregations` parameter. These transformations run identically online and offline which is critical for preventing skew.\n",
    "\n",
    "One of the great things about Tecton is that we can test our features right away using historical data via the `get_features_in_range` method. This helps us validate that everything is working as expected before we start processing real-time data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vAgfm2z6vXNo"
   },
   "outputs": [],
   "source": [
    "from tecton import *\n",
    "from tecton.types import *\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "transactions_stream = StreamSource(\n",
    "    name=\"transactions_stream\",\n",
    "    stream_config=PushConfig(),\n",
    "    batch_config=FileConfig(\n",
    "        uri=\"s3://tecton.ai.public/tutorials/transactions.pq\",\n",
    "        file_format=\"parquet\",\n",
    "        timestamp_field=\"timestamp\",\n",
    "    ),\n",
    "    schema=[Field(\"user_id\", String), Field(\"timestamp\", Timestamp), Field(\"amount\", Float64)],\n",
    ")\n",
    "\n",
    "\n",
    "user = Entity(name=\"user\", join_keys=[Field(\"user_id\", String)])\n",
    "\n",
    "\n",
    "@stream_feature_view(\n",
    "    source=transactions_stream,\n",
    "    entities=[user],\n",
    "    mode=\"pandas\",\n",
    "    timestamp_field=\"timestamp\",\n",
    "    features=[\n",
    "        Aggregate(input_column=Field(\"amount\", Float64), function=\"sum\", time_window=timedelta(minutes=1)),\n",
    "        Aggregate(input_column=Field(\"amount\", Float64), function=\"sum\", time_window=timedelta(hours=1)),\n",
    "        Aggregate(input_column=Field(\"amount\", Float64), function=\"sum\", time_window=timedelta(days=30)),\n",
    "    ],\n",
    ")\n",
    "def user_transaction_amount_totals(transactions_stream):\n",
    "    return transactions_stream[[\"user_id\", \"timestamp\", \"amount\"]]\n",
    "\n",
    "\n",
    "# Test the feature locally using historical data\n",
    "df = (\n",
    "    user_transaction_amount_totals.get_features_in_range(start_time=datetime(2022, 1, 1), end_time=datetime(2022, 2, 1))\n",
    "    .to_pandas()\n",
    "    .fillna(0)\n",
    ")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `_valid_to` and `valid_from` columns specify the time range for which the\n",
    "row of feature values is valid. See\n",
    "[Offline Retrieval Methods](../reading-feature-data/reading-feature-data-for-training/offline-retrieval-methods)\n",
    "for more information.\n",
    "\n",
    "These results show us that our feature is working! For each user, we can see\n",
    "their transaction totals over different time windows. The different windows let\n",
    "us capture both immediate activity (1-minute window), recent patterns (1-hour\n",
    "window), and longer-term behavior (30-day window).\n",
    "\n",
    "In the next section, we'll make this real-time by sending in live data and\n",
    "watching these features update instantly!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kcNDIJH1F5Bf"
   },
   "source": [
    "## ‚ö°Ô∏è Ingest data and retrieve updated feature values in real-time\n",
    "\n",
    "Tecton objects get registered via a [declarative workflow](https://docs.tecton.ai/docs/the-feature-development-workflow#5-copy-definitions-into-your-teams-feature-repository). Features are defined as code in a repo and applied to a workspace (like a project) in a Tecton account using the Tecton CLI. This declarative workflow enables productionization best practices such as \"features as code,\" CI/CD, and unit testing.\n",
    "\n",
    "We've gone ahead and [registered these features](https://explore.tecton.ai/app/repo/prod/features/user_transaction_amount_totals/pipeline) so you can try ingesting new events and querying for online features. After features get registered with a workspace, Tecton handles the [backfilling and ongoing materialization](https://explore.tecton.ai/app/repo/prod/features/user_transaction_amount_totals/materialization) of data to the offline and online store for training and serving.\n",
    "\n",
    "**This step requires generating an API key, which you can do [here](https://explore.tecton.ai/app/settings/accounts-and-access/service-accounts?create-service-account=true). Copy the generated key and paste it in below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uf_VCjfqv6P7"
   },
   "outputs": [],
   "source": [
    "import random, string\n",
    "\n",
    "tecton.login(tecton_url=\"https://explore.tecton.ai\", tecton_api_key=\"your-api-key\") # replace with your API key\n",
    "\n",
    "# Fetch registered Tecton objects\n",
    "ws = tecton.get_workspace(\"prod\")\n",
    "ds = ws.get_data_source(\"transactions_stream\")\n",
    "fv = ws.get_feature_view(\"user_transaction_amount_totals\")\n",
    "\n",
    "# Generate a random user_id for the next step\n",
    "user_id = \"user_\" + \"\".join(random.choices(string.digits, k=7))\n",
    "print(\"Generated random user id: \" + user_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mAplFLQGIvm"
   },
   "source": [
    "### üî• Run this repeatedly and watch the features update!\n",
    "\n",
    "**Note: It may take a few minutes for your API key permissions to update.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QVMJ7UMYwqlT"
   },
   "outputs": [],
   "source": [
    "# Ingest a new transaction with any amount you want\n",
    "record = ds.ingest({\n",
    "    \"user_id\": user_id,\n",
    "    \"timestamp\": datetime.utcnow(),\n",
    "    \"amount\": 100\n",
    "})\n",
    "print(f\"Ingested record for '{user_id}':\")\n",
    "print(record)\n",
    "\n",
    "# Read updated features via Tecton's HTTP API\n",
    "features = fv.get_online_features(join_keys={\"user_id\": user_id}).to_dict()\n",
    "print(f\"\\nUpdated features for '{user_id}':\")\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's where it gets interesting - try running the ingest code multiple times\n",
    "with different amounts! You'll see how the different time windows behave:\n",
    "\n",
    "- The 1-minute window shows the most recent activity - perfect for detecting sudden bursts of transactions\n",
    "- The 1-hour window accumulates transactions over a longer period - useful for identifying short-term patterns\n",
    "- The 30-day window maintains a longer-term view - great for understanding typical user behavior\n",
    "\n",
    "This kind of real-time feature computation is incredibly powerful for:\n",
    "\n",
    "- Fraud detection systems that need to spot unusual spending patterns immediately\n",
    "- Recommendation engines that adapt to user behavior in real-time\n",
    "- Any application where fresh feature values make a difference\n",
    "\n",
    "Under the hood, Tecton is handling all the complexity of:\n",
    "\n",
    "- Streaming data ingestion\n",
    "- Real-time feature computation\n",
    "- Time window management\n",
    "- Low-latency feature serving\n",
    "\n",
    "In a real application, you'd send this data directly to Tecton's HTTP API for the best performance. The `.ingest()` method we're using here is great for testing and development, but for production use cases, you'll want to use the HTTP API directly.\n",
    "\n",
    "Let's wrap up and look at what you've accomplished!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u92v9Q4vIc0R"
   },
   "source": [
    "## ‚≠êÔ∏è Conclusion\n",
    "\n",
    "Congratulations! You've just built a real-time feature pipeline that can:\n",
    "\n",
    "- Ingest streaming transaction data\n",
    "- Calculate features over multiple time windows\n",
    "- Serve feature values with sub-second latency\n",
    "\n",
    "### What We Built\n",
    "\n",
    "- A streaming data source that accepts real-time events\n",
    "- A feature view that computes running totals over three time windows:\n",
    "  - 1 minute (very recent activity)\n",
    "  - 1 hour (recent patterns)\n",
    "  - 30 days (long-term patterns)\n",
    "- A real-time serving endpoint for these features\n",
    "\n",
    "### Key Concepts You've Learned\n",
    "\n",
    "- How to define a `StreamSource` for real-time data\n",
    "- How to create time-windowed aggregation features\n",
    "- How to test features with historical data\n",
    "- How to send and receive real-time updates\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Explore More Features**\n",
    "\n",
    "   - Try different aggregation functions (mean, count, max)\n",
    "   - Add more time windows\n",
    "   - Combine multiple features together\n",
    "\n",
    "2. **Ready for Production?** Try our\n",
    "   [\"Building a Production AI Application\"](https://docs.tecton.ai/docs/tutorials/building-a-production-ai-application)\n",
    "   tutorial to learn:\n",
    "   - How to set up monitoring\n",
    "   - How to generate training data\n",
    "   - Best practices for production deployment\n",
    "\n",
    "[Try Tecton for free](https://www.tecton.ai/explore/)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
