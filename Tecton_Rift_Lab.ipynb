{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tecton-ai/demo-notebooks/blob/main/Tecton_Rift_Lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlsggVTehkiV"
      },
      "source": [
        "# üß™ Lab: Productionizing Real-Time Features with Tecton and Rift\n",
        "\n",
        "In this lab, we will explore how we can develop and test real-time features for a fraud detecton use case using Tecton and Rift.\n",
        "\n",
        "Rift is Tecton's Python-first compute engine for efficiently computing batch, stream, and real-time features using Python and SQL. With Rift we can develop and test features locally in any Python environment and then productionize with a single step.\n",
        "\n",
        "Let's try it out!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFUbSoc8hEr_"
      },
      "source": [
        "## ‚öôÔ∏è Install Pre-Reqs\n",
        "\n",
        "Run the following commands to install Tecton and other pre-requisites.\n",
        "\n",
        "**After installation, be sure to restart your session via \"Runtime -> Restart Session\" in the menu above.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FkL6Pc_MvE4w"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting virtualenv\n",
            "  Downloading virtualenv-20.25.1-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv)\n",
            "  Downloading distlib-0.3.8-py2.py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: filelock<4,>=3.12.2 in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from virtualenv) (3.13.3)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from virtualenv) (3.11.0)\n",
            "Downloading virtualenv-20.25.1-py3-none-any.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
            "\u001b[?25hDownloading distlib-0.3.8-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: distlib, virtualenv\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed distlib-0.3.8 virtualenv-20.25.1\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mcreated virtual environment CPython3.12.2.final.0-64 in 330ms\n",
            "  creator CPython3macOsBrew(dest=/Users/maheshtecton/demo-notebooks/tecton, clear=False, no_vcs_ignore=False, global=False)\n",
            "  seeder FromAppData(download=False, pip=bundle, via=copy, app_data_dir=/Users/maheshtecton/Library/Application Support/virtualenv)\n",
            "    added seed packages: pip==24.0\n",
            "  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: tecton==0.9.0rc3 in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tecton[rift]==0.9.0rc3) (0.9.0rc3)\n",
            "Requirement already satisfied: scikit-learn in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (1.4.0)\n",
            "Requirement already satisfied: attrs>=21.3.0 in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tecton==0.9.0rc3->tecton[rift]==0.9.0rc3) (23.2.0)\n",
            "Requirement already satisfied: boto3 in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tecton==0.9.0rc3->tecton[rift]==0.9.0rc3) (1.34.34)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tecton==0.9.0rc3->tecton[rift]==0.9.0rc3) (1.63.0)\n",
            "Requirement already satisfied: jinja2~=3.0 in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tecton==0.9.0rc3->tecton[rift]==0.9.0rc3) (3.1.3)\n",
            "Collecting numpy~=1.16 (from tecton==0.9.0rc3->tecton[rift]==0.9.0rc3)\n",
            "  Using cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (114 kB)\n",
            "Requirement already satisfied: pathspec in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tecton==0.9.0rc3->tecton[rift]==0.9.0rc3) (0.12.1)\n",
            "Requirement already satisfied: pendulum~=2.1 in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tecton==0.9.0rc3->tecton[rift]==0.9.0rc3) (2.1.2)\n",
            "Requirement already satisfied: protobuf>=3.20.0 in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tecton==0.9.0rc3->tecton[rift]==0.9.0rc3) (4.25.3)\n",
            "Requirement already satisfied: pypika~=0.48.9 in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tecton==0.9.0rc3->tecton[rift]==0.9.0rc3) (0.48.9)\n",
            "Requirement already satisfied: pytimeparse in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tecton==0.9.0rc3->tecton[rift]==0.9.0rc3) (1.1.8)\n",
            "Requirement already satisfied: pandas>=1.0 in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tecton==0.9.0rc3->tecton[rift]==0.9.0rc3) (2.2.1)\n",
            "Requirement already satisfied: texttable in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tecton==0.9.0rc3->tecton[rift]==0.9.0rc3) (1.7.0)\n",
            "Requirement already satisfied: requests in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tecton==0.9.0rc3->tecton[rift]==0.9.0rc3) (2.31.0)\n",
            "Requirement already satisfied: colorama~=0.4 in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tecton==0.9.0rc3->tecton[rift]==0.9.0rc3) (0.4.6)\n",
            "Requirement already satisfied: tqdm~=4.41 in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tecton==0.9.0rc3->tecton[rift]==0.9.0rc3) (4.66.2)\n",
            "Requirement already satisfied: yaspin<3,>=0.16 in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tecton==0.9.0rc3->tecton[rift]==0.9.0rc3) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions~=4.1 in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tecton==0.9.0rc3->tecton[rift]==0.9.0rc3) (4.10.0)\n",
            "Requirement already satisfied: pygments>=2.7.4 in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tecton==0.9.0rc3->tecton[rift]==0.9.0rc3) (2.17.2)\n",
            "Requirement already satisfied: pytest in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tecton==0.9.0rc3->tecton[rift]==0.9.0rc3) (8.1.1)\n",
            "Requirement already satisfied: click~=8.0 in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tecton==0.9.0rc3->tecton[rift]==0.9.0rc3) (8.1.7)\n",
            "Requirement already satisfied: typeguard~=2.0 in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tecton==0.9.0rc3->tecton[rift]==0.9.0rc3) (2.13.3)\n",
            "Requirement already satisfied: sqlparse in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tecton==0.9.0rc3->tecton[rift]==0.9.0rc3) (0.4.4)\n",
            "Requirement already satisfied: semantic-version in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tecton==0.9.0rc3->tecton[rift]==0.9.0rc3) (2.10.0)\n",
            "Requirement already satisfied: pyarrow<15,>=8 in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tecton==0.9.0rc3->tecton[rift]==0.9.0rc3) (14.0.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.10.13 in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tecton==0.9.0rc3->tecton[rift]==0.9.0rc3) (2.6.4)\n",
            "Requirement already satisfied: pyyaml in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tecton==0.9.0rc3->tecton[rift]==0.9.0rc3) (6.0.1)\n",
            "Requirement already satisfied: setuptools in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tecton==0.9.0rc3->tecton[rift]==0.9.0rc3) (69.2.0)\n",
            "Requirement already satisfied: pip in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tecton==0.9.0rc3->tecton[rift]==0.9.0rc3) (24.0)\n",
            "Requirement already satisfied: pex~=2.1 in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tecton==0.9.0rc3->tecton[rift]==0.9.0rc3) (2.3.0)\n",
            "Requirement already satisfied: duckdb==0.10.0 in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tecton[rift]==0.9.0rc3) (0.10.0)\n",
            "Requirement already satisfied: deltalake~=0.15 in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tecton[rift]==0.9.0rc3) (0.15.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from scikit-learn) (1.12.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from scikit-learn) (3.4.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from deltalake~=0.15->tecton[rift]==0.9.0rc3) (0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from jinja2~=3.0->tecton==0.9.0rc3->tecton[rift]==0.9.0rc3) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from pandas>=1.0->tecton==0.9.0rc3->tecton[rift]==0.9.0rc3) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from pandas>=1.0->tecton==0.9.0rc3->tecton[rift]==0.9.0rc3) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from pandas>=1.0->tecton==0.9.0rc3->tecton[rift]==0.9.0rc3) (2024.1)\n",
            "Requirement already satisfied: pytzdata>=2020.1 in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from pendulum~=2.1->tecton==0.9.0rc3->tecton[rift]==0.9.0rc3) (2020.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from pydantic<3,>=1.10.13->tecton==0.9.0rc3->tecton[rift]==0.9.0rc3) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from pydantic<3,>=1.10.13->tecton==0.9.0rc3->tecton[rift]==0.9.0rc3) (2.16.3)\n",
            "Requirement already satisfied: termcolor<3.0,>=2.3 in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from yaspin<3,>=0.16->tecton==0.9.0rc3->tecton[rift]==0.9.0rc3) (2.4.0)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.34 in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from boto3->tecton==0.9.0rc3->tecton[rift]==0.9.0rc3) (1.34.34)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from boto3->tecton==0.9.0rc3->tecton[rift]==0.9.0rc3) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from boto3->tecton==0.9.0rc3->tecton[rift]==0.9.0rc3) (0.10.1)\n",
            "Requirement already satisfied: iniconfig in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from pytest->tecton==0.9.0rc3->tecton[rift]==0.9.0rc3) (2.0.0)\n",
            "Requirement already satisfied: packaging in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from pytest->tecton==0.9.0rc3->tecton[rift]==0.9.0rc3) (24.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=1.4 in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from pytest->tecton==0.9.0rc3->tecton[rift]==0.9.0rc3) (1.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from requests->tecton==0.9.0rc3->tecton[rift]==0.9.0rc3) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from requests->tecton==0.9.0rc3->tecton[rift]==0.9.0rc3) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from requests->tecton==0.9.0rc3->tecton[rift]==0.9.0rc3) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from requests->tecton==0.9.0rc3->tecton[rift]==0.9.0rc3) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.0->tecton==0.9.0rc3->tecton[rift]==0.9.0rc3) (1.16.0)\n",
            "Using cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: numpy\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed numpy\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/Users/maheshtecton/.pyenv/versions/3.11.6/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install virtualenv\n",
        "!virtualenv tecton\n",
        "!source tecton/bin/activate\n",
        "!pip install 'tecton[rift]>=0.9.0' scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQuFAJBGjbi1"
      },
      "source": [
        "‚úÖ Restart your session via \"Runtime -> Restart Session\"\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "## üë©‚Äçüíª Log into a Tecton account"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GRf76TsNtk0x"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "module 'tecton' has no attribute 'login'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime, timedelta\n\u001b[1;32m      8\u001b[0m tecton\u001b[38;5;241m.\u001b[39mset_validation_mode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mtecton\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogin\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlab.tecton.ai\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tecton' has no attribute 'login'"
          ]
        }
      ],
      "source": [
        "import tecton, os, requests, json\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "from tecton import *\n",
        "from tecton.types import *\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "tecton.set_validation_mode('auto')\n",
        "tecton.login('lab.tecton.ai')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "ca360037-6e9e-4fc8-a04f-2d033a3016b6",
          "showTitle": false,
          "title": ""
        },
        "id": "KdIySM8Ztk0y"
      },
      "source": [
        "## üîé Examine Raw Data\n",
        "\n",
        "On S3 we have a historical log of a transaction stream representing transactions that users made at different merchants in the last few years.\n",
        "\n",
        "We can use this data to brainstorm streaming features and even test them out with Tecton!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "70d8ea68-5713-4bb4-8223-f19e486909e5",
          "showTitle": false,
          "title": ""
        },
        "id": "CZtqdn_gtk0z"
      },
      "outputs": [],
      "source": [
        "df = pd.read_parquet(\"s3://tecton.ai.public/tutorials/transactions.pq\", storage_options={'anon': True})\n",
        "\n",
        "display(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "db1ea257-ee04-462e-af92-454d42820bec",
          "showTitle": false,
          "title": ""
        },
        "id": "bdjdca92tk00"
      },
      "source": [
        "## üåä Define and Test Streaming Features\n",
        "\n",
        "Streaming features can be tested offline in a notebook and used to train a model. Tecton uses the historical log of a stream to compute accurate historical feature values.\n",
        "\n",
        "‚úÖ Try extending the definition below with more features, such as:\n",
        "\n",
        "- The total dollar amount of transactions a user has made in the last 1 minute, 5 minutes, and 1 year.\n",
        "- The total number of transactions a user has made in the last 1 minute, 5 minutes, and 1 year.\n",
        "\n",
        "You may find [this documentation](https://docs.tecton.ai/docs/beta/defining-features/feature-views/aggregation-engine/aggregation-functions) helpful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "b4a3ec27-3483-4358-b830-0ab2677ea9e8",
          "showTitle": false,
          "title": ""
        },
        "id": "5k6iqWl1tk00"
      },
      "outputs": [],
      "source": [
        "# Define a stream source, including the historical log of the stream\n",
        "transactions_stream = StreamSource(\n",
        "    name='transactions_stream',\n",
        "    stream_config=PushConfig(),\n",
        "    batch_config=FileConfig(\n",
        "        uri='s3://tecton.ai.public/tutorials/transactions.pq',\n",
        "        file_format='parquet',\n",
        "        timestamp_field='timestamp'\n",
        "    ),\n",
        "    schema=[Field('user_id', String), Field('timestamp', Timestamp), Field('amt', Float64)]\n",
        ")\n",
        "\n",
        "# Define the entity we are creating features for\n",
        "user = Entity(name='user', join_keys=['user_id'])\n",
        "\n",
        "# Define features\n",
        "@stream_feature_view(\n",
        "    source=transactions_stream,\n",
        "    entities=[user],\n",
        "    mode='pandas',\n",
        "    aggregations=[\n",
        "        Aggregation(function='mean', column='amt', time_window=timedelta(minutes=1)),\n",
        "        Aggregation(function='mean', column='amt', time_window=timedelta(minutes=5)),\n",
        "        Aggregation(function='mean', column='amt', time_window=timedelta(days=365))\n",
        "    ],\n",
        "    schema=[Field(\"user_id\", String), Field(\"timestamp\", Timestamp), Field(\"amt\", Float64)]\n",
        ")\n",
        "def user_transaction_features(transactions):\n",
        "    return transactions[['user_id', 'timestamp', 'amt']]\n",
        "\n",
        "\n",
        "# Compute features\n",
        "start = datetime(2023,1,1)\n",
        "end = datetime(2023,6,1)\n",
        "\n",
        "feature_df = user_transaction_features.get_historical_features(start_time=start, end_time=end).to_pandas()\n",
        "\n",
        "display(feature_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhqBa92Nep2l"
      },
      "source": [
        "## ‚è±Ô∏è Define and Test Real-Time Features\n",
        "\n",
        "Now let's define a feature that checks if the current transaction amount a user is seeking to make is higher than their historical average.\n",
        "\n",
        "Because this feature depends on real-time info (the current transaction amount), we need to compute it at the time of the request. That's exactly where on-demand features come in.\n",
        "\n",
        "‚úÖ Try changing the definition below to compare the transaction to the 1 year average instead of the 5 minute average."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojMVzfG26nRS"
      },
      "outputs": [],
      "source": [
        "# Define on-demand features\n",
        "transaction_request = RequestSource(schema=[Field(\"amt\", Float64)])\n",
        "\n",
        "@on_demand_feature_view(\n",
        "    sources=[transaction_request, user_transaction_features],\n",
        "    mode=\"python\",\n",
        "    schema=[Field(\"transaction_amount_is_higher_than_average\", Bool)],\n",
        ")\n",
        "def transaction_amount_is_higher_than_average(transaction_request, user_transaction_features):\n",
        "    amount_mean = user_transaction_features[\"amt_mean_5m_continuous\"]\n",
        "    amount_mean = 0 if amount_mean is None else amount_mean\n",
        "    return {\"transaction_amount_is_higher_than_average\": transaction_request[\"amt\"] > amount_mean}\n",
        "\n",
        "\n",
        "# Test on-demand features\n",
        "averages = feature_df.drop(columns=['user_id', 'timestamp', '_effective_timestamp']).iloc[0].to_dict()\n",
        "request = {'amt': 10.4}\n",
        "features = transaction_amount_is_higher_than_average.run(transaction_request=request, user_transaction_features=averages)\n",
        "\n",
        "print('\\nRequest amount: ' + str(request['amt']))\n",
        "print('Average: ' + str(averages['amt_mean_5m_continuous']))\n",
        "print(str(features))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "4367e3a5-0942-42d9-81b4-9221cd8b2d97",
          "showTitle": false,
          "title": ""
        },
        "id": "2MH1xogXtk00"
      },
      "source": [
        "## üßÆ Generate Training Data\n",
        "\n",
        "Now that we've created some features, it's time to join them into a training data set so we can train a model.\n",
        "\n",
        "First let's load up a list of historical training events. These events represent labeled historical user transactions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "3037c380-6a48-4ad6-93af-0e2ae369b9b7",
          "showTitle": false,
          "title": ""
        },
        "id": "JEY5-btgtk01"
      },
      "outputs": [],
      "source": [
        "training_events = pd.read_parquet(\"s3://tecton.ai.public/tutorials/fraud_demo/transactions/data.pq\", storage_options={'anon': True}) \\\n",
        "                    [['user_id', 'timestamp', 'amt', 'is_fraud']]\n",
        "\n",
        "display(training_events)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c9EhlkHpjlB"
      },
      "source": [
        "Now that we have our training events, we can get features for those events by adding them to a Feature Service and calling `get_historical_features(events)`.\n",
        "\n",
        "The feature service defines the set of features we want to serve to our model offline and online."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "6cb99278-9306-41f4-9579-d49558bf6546",
          "showTitle": false,
          "title": ""
        },
        "id": "ybav_BHTtk01"
      },
      "outputs": [],
      "source": [
        "from tecton import FeatureService\n",
        "\n",
        "fraud_detection_feature_service = FeatureService(\n",
        "    name=\"fraud_detection_feature_service\",\n",
        "    features=[user_transaction_features, transaction_amount_is_higher_than_average]\n",
        ")\n",
        "\n",
        "training_data = fraud_detection_feature_service.get_historical_features(training_events).to_pandas()\n",
        "\n",
        "display(training_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cuzkl3dQisp3"
      },
      "source": [
        "## üß† Train a Model\n",
        "\n",
        "With a training dataset full of features, we can now train a simple logistic regression model to detect fraudulent transactions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPdMChnoDayD"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "\n",
        "df = training_data.drop(['user_id', 'timestamp', 'amt'], axis=1)\n",
        "\n",
        "X = df.drop('is_fraud', axis=1)\n",
        "y = df['is_fraud']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "num_cols = X_train.select_dtypes(exclude=['object']).columns.tolist()\n",
        "cat_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "num_pipe = make_pipeline(\n",
        "    SimpleImputer(strategy='median'),\n",
        "    StandardScaler()\n",
        ")\n",
        "\n",
        "cat_pipe = make_pipeline(\n",
        "    SimpleImputer(strategy='constant', fill_value='N/A'),\n",
        "    OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        ")\n",
        "\n",
        "full_pipe = ColumnTransformer([\n",
        "    ('num', num_pipe, num_cols),\n",
        "    ('cat', cat_pipe, cat_cols)\n",
        "])\n",
        "\n",
        "model = make_pipeline(full_pipe, LogisticRegression(max_iter=1000, random_state=42))\n",
        "\n",
        "model.fit(X_train,y_train)\n",
        "\n",
        "y_predict = model.predict(X_test)\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0xnpaWbtk01"
      },
      "source": [
        "## üöÄ Apply Features to Production\n",
        "\n",
        "**NOTE: This step has been done for you already.**\n",
        "\n",
        "Productionizing features with Tecton is easy. Simply paste the definitions into a repo of Python files, select a workspace, and run `tecton apply to productize\n",
        "\n",
        "Create a feature repo:\n",
        "```bash\n",
        "mkdir feature-repo && cd feature-repo\n",
        "tecton init\n",
        "touch features.py\n",
        "```\n",
        "\n",
        "Apply features to production:\n",
        "```bash\n",
        "tecton login lab.tecton.ai\n",
        "tecton workspace select prod\n",
        "tecton apply\n",
        "```\n",
        "\n",
        "You can check out the applied features in Tecton's web UI [here](https://lab.tecton.ai/app/repo/prod/features).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wm-D0A-Ptk01"
      },
      "source": [
        "## ‚ö°Ô∏è Ingest Streaming Events and Read Real-Time Features\n",
        "\n",
        "Once we've productionized our Stream Source, we can start sending events to it. Any features defined against this source will be updated in real time!\n",
        "\n",
        "Try adding your own name as the `user_id` below and watch how feature values update immediately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5e44pRLtUt56"
      },
      "outputs": [],
      "source": [
        "tecton.set_credentials(tecton_api_key='')\n",
        "os.environ['TECTON_API_KEY'] = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOqfHswztk01"
      },
      "outputs": [],
      "source": [
        "ws = tecton.get_workspace('prod')\n",
        "registered_transactions_stream = ws.get_data_source('transactions_stream')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGAYs7vatk01"
      },
      "outputs": [],
      "source": [
        "registered_transactions_stream.ingest({\n",
        "    'user_id': 'lab-user',\n",
        "    'timestamp': datetime.utcnow(),\n",
        "    'amt': 50.00\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRDcCdOetk01"
      },
      "outputs": [],
      "source": [
        "fs = ws.get_feature_service('fraud_detection_feature_service')\n",
        "features = fs.get_online_features(join_keys={'user_id': 'mahesh'}, request_data={'amt': 50}).to_dict()\n",
        "\n",
        "pprint(features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qs4j0u72GjjZ"
      },
      "source": [
        "## üî• Define Online Prediction Pipeline\n",
        "\n",
        "Now that we have online feature values, we can create a prediction pipeline to determine if a transaction is fraudulent and whether we should accept or reject it.\n",
        "\n",
        "To do this we will define three functions to:\n",
        "\n",
        "1. Get features from Tecton\n",
        "2. Use the real-time features to make a prediction with the model\n",
        "3. Use the model prediction to accept or reject a transaction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DsoofOr-NpRM"
      },
      "outputs": [],
      "source": [
        "# Get features from Tecton\n",
        "def get_online_feature_data(user_id, amt):\n",
        "    headers = {\"Authorization\": \"Tecton-key \" + os.environ['TECTON_API_KEY']}\n",
        "\n",
        "    request_data = f'''{{\n",
        "        \"params\": {{\n",
        "            \"feature_service_name\": \"fraud_detection_feature_service\",\n",
        "            \"join_key_map\": {{\"user_id\": \"{user_id}\"}},\n",
        "            \"metadata_options\": {{\"include_names\": true}},\n",
        "            \"request_context_map\": {{\"amt\": {amt}}},\n",
        "            \"workspace_name\": \"prod\"\n",
        "        }}\n",
        "    }}'''\n",
        "\n",
        "    online_feature_data = requests.request(\n",
        "        method=\"POST\",\n",
        "        headers=headers,\n",
        "        url=\"https://lab.tecton.ai/api/v1/feature-service/get-features\",\n",
        "        data=request_data,\n",
        "    )\n",
        "\n",
        "    online_feature_data_json = json.loads(online_feature_data.text)\n",
        "\n",
        "    return online_feature_data_json\n",
        "\n",
        "# Use the real-time features to make a prediction with the model\n",
        "def get_prediction_from_model(feature_data):\n",
        "    columns = [f[\"name\"].replace(\".\", \"__\") for f in feature_data[\"metadata\"][\"features\"]]\n",
        "    data = [feature_data[\"result\"][\"features\"]]\n",
        "\n",
        "    features = pd.DataFrame(data, columns=columns)\n",
        "\n",
        "    return model.predict(features)[0]\n",
        "\n",
        "# Use the model prediction to accept or reject a transaction\n",
        "def evaluate_transaction(user_id, amt):\n",
        "    online_feature_data = get_online_feature_data(user_id, amt)\n",
        "    is_predicted_fraud = get_prediction_from_model(online_feature_data)\n",
        "\n",
        "    print('Features: ' + str(online_feature_data[\"result\"][\"features\"]))\n",
        "    print('Model Score: ' + str(is_predicted_fraud))\n",
        "\n",
        "    if is_predicted_fraud == 0:\n",
        "        print('Transaction accepted.')\n",
        "    else:\n",
        "        print('Transaction denied.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6cJ46vhHSyB"
      },
      "source": [
        "## ‚≠êÔ∏è Evaluate Transactions in Real-Time\n",
        "\n",
        "Now we have a single decision API to evaluate transactions in real-time!\n",
        "\n",
        "Let's test it out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LP2M-xlFiJZ"
      },
      "outputs": [],
      "source": [
        "evaluate_transaction('lab-user', 16)"
      ]
    }
  ],
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "dashboards": [],
      "language": "python",
      "notebookMetadata": {
        "pythonIndentUnit": 2
      },
      "notebookName": "Tecton Demo",
      "widgets": {}
    },
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "unified-tecton",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.undefined"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
