{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyOflZFtPkJQYNuk9G8p83Nr",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/tecton-ai/demo-notebooks/blob/main/Tecton_Building_On_Demand_Features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ⏱️ Building On-Demand Features\n",
    "\n",
    "---\n",
    "\n",
    "##### 💡 **NOT YET A TECTON USER?**\n",
    "\n",
    "Sign-up at [explore.tecton.ai](https://explore.tecton.ai) for a free account that lets you try out this tutorial and explore Tecton's Web UI.\n",
    "\n",
    "---\n",
    "\n",
    "Many critical features for real-time models can only be calculated at the time of a request, either because:\n",
    "\n",
    "1.   They require data that is only available at request time (e.g. a user's current location)\n",
    "2.   They can't efficiently be pre-computed (e.g. computing the embedding similarity between all possible users)\n",
    "\n",
    "Running transformations at request time can also be useful for:\n",
    "\n",
    "\n",
    "1.   Post-processing feature data (example: imputing null values)\n",
    "2.   Running additional transformations after Tecton-managed aggregations\n",
    "3.   Defining new features without needing to rematerialize Feature Store data\n",
    "\n",
    "For more details, see [On-Demand Feature Views](https://docs.tecton.ai/docs/defining-features/feature-views/on-demand-feature-view).\n",
    "\n",
    "\n",
    "This is where \"On-Demand\" features come in. In Tecton, an On-Demand Feature View let's you calculate features at the time of a request, using either data passed in with the request or pre-computed batch and stream features.\n",
    "\n",
    "This tutorial will show how you can develop, test, and productionize on-demand features for real-time models. This tutorial is centered around a fraud detection use case, where we need to predict in real-time whether a transaction that a user is making is fraudulent.\n",
    "\n",
    "---\n",
    "\n",
    "##### 🗒️ **NOTE**\n",
    "\n",
    "This tutorial assumes some basic familiarity with Tecton. If you are new to Tecton, we recommend first checking out the [Building a Production AI Application with Tecton](https://docs.tecton.ai/docs/tutorials/building-a-production-ai-application) which walks through an end-to-end journey of building a real-time ML application with Tecton.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## ⚙️ Install Pre-Reqs\n",
    "\n",
    "First things first, let's install the Tecton SDK and other libraries used in this tutorial by running the cell below."
   ],
   "metadata": {
    "id": "yMfPt-wr3xXf"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "7JO9rCZQ2g5m"
   },
   "outputs": [],
   "source": [
    "!pip install 'tecton[rift]==1.0.0' gcsfs s3fs -q"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ✅ Log in to Tecton"
   ],
   "metadata": {
    "id": "Ibs4a_tI958I"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "\n",
    "Next we will authenticate with your organization's Tecton account and import libraries we will need.\n",
    "\n",
    "For users that just signed up via `explore.tecton.ai` you can leave this step as\n",
    "is. If your organization has its own Tecton account, replace\n",
    "`explore.tecton.ai` with your account url.\n",
    "\n",
    "*Note: You need to press `enter` after pasting in your authentication code.*"
   ],
   "metadata": {
    "id": "-Hk3Jz-J6CQG"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import tecton\n",
    "\n",
    "tecton.login(\"explore.tecton.ai\")  # replace with your URL"
   ],
   "metadata": {
    "id": "6k62kbnk919E"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's then run some basic imports and setup that we will use later in the tutorial."
   ],
   "metadata": {
    "id": "1UKGF0onAV7m"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from tecton import *\n",
    "from tecton.types import *\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "tecton.conf.set(\"TECTON_OFFLINE_RETRIEVAL_COMPUTE_MODE\", \"rift\")"
   ],
   "metadata": {
    "id": "JLr_cbma6Dy0"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 👩‍💻 Create an on-demand feature that leverages request data\n",
    "\n",
    "Let's say that for our fraud detection model, we want to be able to leverage information about the user's current transaction that we are evaluating. We only have access to that information at the time of evaluation so any features derived from current transaction information need to be computed in real-time.\n",
    "\n",
    "On-Demand Feature Views are able to leverage real-time request data for building features. In this case, we will do a very simple check to see if the current transaction amount is over $1000. This is a pretty basic feature, but in the next section we will look at how to make it better!\n",
    "\n",
    "To define an on-demand feature that leverages request data, we first define a Request Source. The Request Source specifies the expected schema for the data that will be passed in with the request.\n",
    "\n",
    "##### ℹ️ **INFO**\n",
    "When using mode='python' the inputs and outputs of the On-Demand Feature View are dictionaries.\n",
    "\n",
    "For more information on modes in On Demand Feature Views see [On-Demand Feature Views](https://docs.tecton.ai/docs/defining-features/feature-views/on-demand-feature-view#how-to-choose-between-pandas-and-python-mode).\n",
    "\n",
    "---"
   ],
   "metadata": {
    "id": "ezooQRWl6dtq"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "transaction_request = RequestSource(schema=[Field(\"amount\", Float64)])\n",
    "\n",
    "\n",
    "@on_demand_feature_view(\n",
    "    sources=[transaction_request],\n",
    "    mode=\"python\",\n",
    "    schema=[Field(\"transaction_amount_is_high\", Bool)],\n",
    ")\n",
    "def transaction_amount_is_high(transaction_request):\n",
    "    return {\"transaction_amount_is_high\": transaction_request[\"amount\"] > 1000}"
   ],
   "metadata": {
    "id": "0tgwaolW7Cls"
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we've defined our feature, we can test it out with some mock data using\n",
    "`.run_transformation()`.\n"
   ],
   "metadata": {
    "id": "V8YDjzX97RyZ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "input_data = {\"transaction_request\": {\"amount\": 182.4}}\n",
    "\n",
    "transaction_amount_is_high.run_transformation(input_data=input_data)"
   ],
   "metadata": {
    "collapsed": true,
    "id": "Mtzh15-P8CJt"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "This feature is okay, but wouldn't it be much better if we could compare the transaction amount to the user's historical average?"
   ],
   "metadata": {
    "id": "yyQ53F928TuN"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 🔗 Create an on-demand feature that leverages request data and other features\n",
    "\n",
    "On-Demand Feature Views also have the ability to depend on Batch and Stream Feature Views as input data sources. We can use this capability to improve our feature. Let's take a look.\n",
    "\n",
    "First we will create a Batch Feature View that computes the user's 1-year average transaction amount. Then we will add this as a source in a new On-Demand Feature View with an updated feature transformation."
   ],
   "metadata": {
    "id": "JM6gGYfp8I51"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "transactions_batch = BatchSource(\n",
    "    name=\"transactions_batch\",\n",
    "    batch_config=FileConfig(\n",
    "        uri=\"s3://tecton.ai.public/tutorials/transactions.pq\",\n",
    "        file_format=\"parquet\",\n",
    "        timestamp_field=\"timestamp\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "user = Entity(name=\"user\", join_keys=[\"user_id\"])\n",
    "\n",
    "\n",
    "@batch_feature_view(\n",
    "    sources=[transactions_batch],\n",
    "    entities=[user],\n",
    "    mode=\"pandas\",\n",
    "    aggregation_interval=timedelta(days=1),\n",
    "    aggregations=[\n",
    "        Aggregation(function=\"mean\", column=\"amount\", time_window=timedelta(days=365), name=\"yearly_average\"),\n",
    "    ],\n",
    "    schema=[Field(\"user_id\", String), Field(\"timestamp\", Timestamp), Field(\"amount\", Float64)],\n",
    ")\n",
    "def user_transaction_averages(transactions):\n",
    "    return transactions[[\"user_id\", \"timestamp\", \"amount\"]]\n",
    "\n",
    "\n",
    "transaction_request = RequestSource(schema=[Field(\"amount\", Float64)])\n",
    "\n",
    "\n",
    "@on_demand_feature_view(\n",
    "    sources=[transaction_request, user_transaction_averages],\n",
    "    mode=\"python\",\n",
    "    schema=[Field(\"transaction_amount_is_higher_than_average\", Bool)],\n",
    ")\n",
    "def transaction_amount_is_higher_than_average(transaction_request, user_transaction_averages):\n",
    "    amount_mean = user_transaction_averages[\"yearly_average\"] or 0\n",
    "    return {\"transaction_amount_is_higher_than_average\": transaction_request[\"amount\"] > amount_mean}"
   ],
   "metadata": {
    "id": "5CRjC3lZ8afQ"
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can again test our new feature using `.run_transformation()` and passing in\n",
    "example data."
   ],
   "metadata": {
    "id": "A94ln7sF8fX3"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "input_data = {\"transaction_request\": {\"amount\": 182.4}, \"user_transaction_averages\": {\"yearly_average\": 33.46}}\n",
    "\n",
    "transaction_amount_is_higher_than_average.run_transformation(input_data=input_data)"
   ],
   "metadata": {
    "id": "4IQcOgSA8dKv"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Great! Now that this feature looks to be doing what we want, let's see how we can generate training data with it."
   ],
   "metadata": {
    "id": "-al8KHDW8kw0"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 🧮 Generating Training Data with On-Demand Features\n",
    "\n",
    "When generating training datasets for on-demand features, Tecton uses the exact same transformation logic as it does online to eliminate online/offline skew.\n",
    "\n",
    "The Python function you defined will be executed as a UDF on the training data set.\n",
    "\n",
    "To see this in action, we will first load up a set of historical training events.\n",
    "\n",
    "##### ℹ️ **INFO**\n",
    "\n",
    "Tecton expects that any request data passed in online is present in the set of historical training events. In our example below, this is represented by the amount column.\n",
    "\n",
    "---"
   ],
   "metadata": {
    "id": "oPCQd3Yy8vVN"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Retrieve our dataset of historical transaction data\n",
    "transactions_df = pd.read_parquet(\"s3://tecton.ai.public/tutorials/transactions.pq\", storage_options={\"anon\": True})\n",
    "\n",
    "# Retrieve our dataset of labels containing transaction_id and is_fraud (set to 1 if the transaction is fraudulent or 0 otherwise)\n",
    "training_labels = pd.read_parquet(\"s3://tecton.ai.public/tutorials/labels.pq\", storage_options={\"anon\": True})\n",
    "\n",
    "# Join our label dataset to our transaction data to produce a list of training events\n",
    "training_events = training_labels.merge(transactions_df, on=[\"transaction_id\"], how=\"left\")[\n",
    "    [\"user_id\", \"timestamp\", \"amount\", \"is_fraud\"]\n",
    "]\n",
    "\n",
    "display(training_events.head(5))"
   ],
   "metadata": {
    "id": "SmGpznYj8--t"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can add our On-Demand Feature View to a Feature Service and generate training data for these historical events.\n",
    "\n",
    "##### 🗒️ **NOTE**\n",
    "\n",
    "We included the dependent Batch Feature View in the Feature Service as well to visualize the data better, but it is not necessary to include.\n",
    "\n",
    "---"
   ],
   "metadata": {
    "id": "DjLVl01H9CHc"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from tecton import FeatureService\n",
    "\n",
    "\n",
    "fraud_detection_feature_service = FeatureService(\n",
    "    name=\"fraud_detection_feature_service\",\n",
    "    features=[user_transaction_averages, transaction_amount_is_higher_than_average],\n",
    ")\n",
    "\n",
    "training_data = fraud_detection_feature_service.get_features_for_events(training_events).to_pandas().fillna(0)\n",
    "display(training_data.head(5))"
   ],
   "metadata": {
    "id": "gzXOClry9PGa"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can use this training data set to train an accurate model with our new feature."
   ],
   "metadata": {
    "id": "DEXF8hgS_Blt"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once we are happy with our On-Demand Feature View we can copy the definitions into our Feature Repository and apply our changes to a live workspace using the Tecton CLI.\n",
    "\n",
    "Follow the [instructions](https://docs.tecton.ai/docs/tutorials/building-on-demand-features#-run-on-demand-features-in-production)\n",
    "to run on-demand features in production."
   ],
   "metadata": {
    "id": "NJzwJ-Bk_Dk-"
   }
  }
 ]
}
